[‚Üê Back to overview](../README.md)

# Deep Learning (DL)
We recommend to firstly start with one or two [Machine Learning classes](ML.md), because Deep Learning is related to them and it will be easier for you.

## Courses
* The most recommended is [Andrew Ng's deeplearning.ai class](https://www.deeplearning.ai/)

## Libraries and Frameworks
If you don't know which DL library to start with, we suggest you to check [Ranking Popular DL Libraries](https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/) from 10/2017 where the winner is [Tensorflow](https://www.tensorflow.org/), followed by [Keras](https://keras.io/) and [Caffe](http://caffe.berkeleyvision.org/).


Library | Rank | Overall | Github | Stack Overflow | Google Results
------- | ---- |-------- | ------ | -------------- | --------------
[Tensorflow](https://www.tensorflow.org/) | 1 | 10.8676777173 | 4.25282914794 | 4.371905768 | 2.24294280139
[Keras](https://keras.io/) | 2 | 1.92768682345 | 0.613405340454 | 0.830444013135 | 0.483837469861
[Caffe](http://caffe.berkeleyvision.org/) | 3 | 1.85536658344 | 1.00172325244 | 0.301598379669 | 0.552044951334

<details>
<summary>All 23 libraries and their usage (based on <a href="https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/">Data Incubator ranking</a>)</summary>

Library | Rank | Overall | Github | Stack Overflow | Google Results
------- | ---- |-------- | ------ | -------------- | --------------
[Tensorflow](https://www.tensorflow.org/) | 1 | 10.8676777173 | 4.25282914794 | 4.371905768 | 2.24294280139
[Keras](https://keras.io/) | 2 | 1.92768682345 | 0.613405340454 | 0.830444013135 | 0.483837469861
[Caffe](http://caffe.berkeleyvision.org/) | 3 | 1.85536658344 | 1.00172325244 | 0.301598379669 | 0.552044951334
[Theano](http://deeplearning.net/software/theano/) | 4 | 0.757142065184 | -0.156657475854 | 0.361637072631 | 0.552162468406
[Pytorch](http://pytorch.org/) | 5 | 0.481418742361 | -0.198079135346 | -0.30225967424 | 0.981757551946
[Sonnet](https://github.com/deepmind/sonnet) | 6 | 0.427865682184 | -0.326074511957 | -0.361634296039 | 1.11557449018
[Mxnet](https://mxnet.incubator.apache.org/) | 7 | 0.0987996914674 | 0.121327235453 | -0.306328604959 | 0.283801060973
[Torch](http://torch.ch/) | 8 | 0.00559731666893 | -0.153332101969 | -0.00824393023136 | 0.167173348869
[Cntk](https://github.com/Microsoft/CNTK) | 9 | -0.0205203098963 | 0.0965088202554 | -0.282173869559 | 0.165144739407
[Dlib](http://dlib.net/ml.html) | 10 | -0.599823512154 | -0.39578194316 | -0.223382454956 | 0.0193408859617
[Caffe2](https://github.com/caffe2) | 11 | -0.671062928351 | -0.274071118159 | -0.359648165565 | -0.0373436446266
[Chainer](https://chainer.org/) | 12 | -0.70151841136 | -0.400397905813 | -0.234603397931 | -0.0665171076164
[Paddlepaddle](https://github.com/PaddlePaddle/Paddle) | 13 | -0.833003782881 | -0.267123408237 | -0.366884083295 | -0.198996291348
[Deeplearning4j](https://deeplearning4j.org/) | 14 | -0.893319117931 | -0.0575131634759 | -0.321347169592 | -0.514458784863
[Lasagne](https://lasagne.readthedocs.io/) | 15 | -1.10606125475 | -0.381150749139 | -0.287853956451 | -0.437056549158
[Bigdl](https://github.com/intel-analytics/BigDL) | 16 | -1.12821350465 | -0.458674544538 | -0.367555905286 | -0.301983054824
[Dynet](https://github.com/clab/dynet) | 17 | -1.25088837288 | -0.465671394541 | -0.367690269684 | -0.417526708658
[Apache Singa](https://singa.incubator.apache.org/) | 18 | -1.33963459336 | -0.502246959001 | -0.367824634082 | -0.469563000276
[Nvidia Digits](https://developer.nvidia.com/digits) | 19 | -1.39248467556 | -0.407011549848 | -0.346078273813 | -0.639394851898
[Matconvnet](http://www.vlfeat.org/matconvnet/) | 20 | -1.41327975079 | -0.487125591647 | -0.346308395531 | -0.579845763615
[Tflearn](http://tflearn.org/) | 21 | -1.44982650865 | -0.226089464016 | -0.282710110548 | -0.941026934086
[Nervana Neon](https://github.com/NervanaSystems/neon) | 22 | -1.65176202195 | -0.39497574163 | -0.366989720498 | -0.889796559818
[Opennn](http://www.opennn.net/) | 23 | -1.97015587693 | -0.53381703821 | -0.366068321175 | -1.07027051754

</details>

## Curated Lists
* [A guide to DL](http://yerevann.com/a-guide-to-deep-learning/) is very handy because all concepts are ranked by its difficulty
* [Awesome DL](https://github.com/ChristosChristofidis/awesome-deep-learning)

## Books
* [Deep Learning Book](http://www.deeplearningbook.org/),  Ian Goodfellow, Yoshua Bengio and Aaron Courville, Free
* [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/), Michael Nielsen, Free

## Researchers to follow
* [Geoffrey Hinton](http://www.cs.toronto.edu/~hinton/nntut.html)
* [Andrew Karpathay](http://cs.stanford.edu/people/karpathy/)
* [Richard Socher](http://www.socher.org/)
* [Hugo Larochelle](https://research.google.com/pubs/105144.html)
* [Nando de Freitas](https://www.cs.ox.ac.uk/people/nando.defreitas/)

## Scientific Papers
Based on [Awesome DL Papers](https://github.com/terryum/awesome-deep-learning-papers#reinforcement-learning--robotics), counted since 2012 (last 5 years).

### Understanding, Generalization, Transfer
- [Distilling the knowledge in a neural network (2015), G. Hinton et al.](http://arxiv.org/pdf/1503.02531)
- [Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), A. Nguyen et al.](http://arxiv.org/pdf/1412.1897)
- [How transferable are features in deep neural networks? (2014), J. Yosinski et al.](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)
- [CNN features off-the-Shelf: An astounding baseline for recognition (2014), A. Razavian et al.](http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf)
- [Learning and transferring mid-Level image representations using convolutional neural networks (2014), M. Oquab et al.](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)
- [Visualizing and understanding convolutional networks (2014), M. Zeiler and R. Fergus](http://arxiv.org/pdf/1311.2901)
- [Decaf: A deep convolutional activation feature for generic visual recognition (2014), J. Donahue et al.](http://arxiv.org/pdf/1310.1531)

### Optimization, Training Techniques
- [Training very deep networks (2015), R. Srivastava et al.](http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf)
- [Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), S. Loffe and C. Szegedy](http://arxiv.org/pdf/1502.03167)
- [Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015), K. He et al.](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)
- [Dropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al.](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)
- [Adam: A method for stochastic optimization (2014), D. Kingma and J. Ba](http://arxiv.org/pdf/1412.6980)
- [Improving neural networks by preventing co-adaptation of feature detectors (2012), G. Hinton et al.](http://arxiv.org/pdf/1207.0580.pdf)
- [Random search for hyper-parameter optimization (2012) J. Bergstra and Y. Bengio](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a)

### Unsupervised, Generative Models
- [Pixel recurrent neural networks (2016), A. Oord et al.](http://arxiv.org/pdf/1601.06759v2.pdf)
- [Improved techniques for training GANs (2016), T. Salimans et al.](http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf)
- [Unsupervised representation learning with deep convolutional generative adversarial networks (2015), A. Radford et al.](https://arxiv.org/pdf/1511.06434v2)
- [DRAW: A recurrent neural network for image generation (2015), K. Gregor et al.](http://arxiv.org/pdf/1502.04623)
- [Generative adversarial nets (2014), I. Goodfellow et al.](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)
- [Auto-encoding variational Bayes (2013), D. Kingma and M. Welling](http://arxiv.org/pdf/1312.6114)
- [Building high-level features using large scale unsupervised learning (2013), Q. Le et al.](http://arxiv.org/pdf/1112.6209)

### Convolutional Neural Network Models
- [Rethinking the inception architecture for computer vision (2016), C. Szegedy et al.](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)
- [Inception-v4, inception-resnet and the impact of residual connections on learning (2016), C. Szegedy et al.](http://arxiv.org/pdf/1602.07261)
- [Identity Mappings in Deep Residual Networks (2016), K. He et al.](https://arxiv.org/pdf/1603.05027v2.pdf)
- [Deep residual learning for image recognition (2016), K. He et al.](http://arxiv.org/pdf/1512.03385)
- [Spatial transformer network (2015), M. Jaderberg et al.,](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)
- [Going deeper with convolutions (2015), C. Szegedy et al. ](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)
- [Very deep convolutional networks for large-scale image recognition (2014), K. Simonyan and A. Zisserman](http://arxiv.org/pdf/1409.1556)
- [Return of the devil in the details: delving deep into convolutional nets (2014), K. Chatfield et al.](http://arxiv.org/pdf/1405.3531)
- [OverFeat: Integrated recognition, localization and detection using convolutional networks (2013), P. Sermanet et al.](http://arxiv.org/pdf/1312.6229)
- [Maxout networks (2013), I. Goodfellow et al.](http://arxiv.org/pdf/1302.4389v4)
- [Network in network (2013), M. Lin et al.](http://arxiv.org/pdf/1312.4400)
- [ImageNet classification with deep convolutional neural networks (2012), A. Krizhevsky et al.](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

## Capsule Networks
  * [Aur√©lien G√©ron's tutorial](https://youtu.be/pPN8d0E3900)
